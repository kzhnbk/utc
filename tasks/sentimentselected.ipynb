{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":16295,"databundleVersionId":1099992,"sourceType":"competition"}],"dockerImageVersionId":31041,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-26T06:48:42.228674Z","iopub.execute_input":"2025-06-26T06:48:42.228969Z","iopub.status.idle":"2025-06-26T06:48:42.236102Z","shell.execute_reply.started":"2025-06-26T06:48:42.228949Z","shell.execute_reply":"2025-06-26T06:48:42.235405Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/tweet-sentiment-extraction/sample_submission.csv\n/kaggle/input/tweet-sentiment-extraction/train.csv\n/kaggle/input/tweet-sentiment-extraction/test.csv\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"def jaccard(str1, str2):\n    a = set(str1.lower().split())\n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T06:48:42.397897Z","iopub.execute_input":"2025-06-26T06:48:42.398156Z","iopub.status.idle":"2025-06-26T06:48:42.402518Z","shell.execute_reply.started":"2025-06-26T06:48:42.398138Z","shell.execute_reply":"2025-06-26T06:48:42.401757Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\ntest = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')\nsubm = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/sample_submission.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T06:48:42.605525Z","iopub.execute_input":"2025-06-26T06:48:42.606051Z","iopub.status.idle":"2025-06-26T06:48:42.684468Z","shell.execute_reply.started":"2025-06-26T06:48:42.606028Z","shell.execute_reply":"2025-06-26T06:48:42.683743Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"train = train.dropna()\ntrain","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T06:49:34.992805Z","iopub.execute_input":"2025-06-26T06:49:34.993128Z","iopub.status.idle":"2025-06-26T06:49:35.013071Z","shell.execute_reply.started":"2025-06-26T06:49:34.993105Z","shell.execute_reply":"2025-06-26T06:49:35.012498Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"           textID                                               text  \\\n0      cb774db0d1                I`d have responded, if I were going   \n1      549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n2      088c60f138                          my boss is bullying me...   \n3      9642c003ef                     what interview! leave me alone   \n4      358bd9e861   Sons of ****, why couldn`t they put them on t...   \n...           ...                                                ...   \n27476  4eac33d1c0   wish we could come see u on Denver  husband l...   \n27477  4f4c4fc327   I`ve wondered about rake to.  The client has ...   \n27478  f67aae2310   Yay good for both of you. Enjoy the break - y...   \n27479  ed167662a5                         But it was worth it  ****.   \n27480  6f7127d9d7     All this flirting going on - The ATG smiles...   \n\n                                           selected_text sentiment  \\\n0                    I`d have responded, if I were going   neutral   \n1                                               Sooo SAD  negative   \n2                                            bullying me  negative   \n3                                         leave me alone  negative   \n4                                          Sons of ****,  negative   \n...                                                  ...       ...   \n27476                                             d lost  negative   \n27477                                      , don`t force  negative   \n27478                          Yay good for both of you.  positive   \n27479                         But it was worth it  ****.  positive   \n27480  All this flirting going on - The ATG smiles. Y...   neutral   \n\n                                                    pred  \n0                    I`d have responded, if I were going  \n1                                             sooo sad i  \n2                                       boss is bullying  \n3                                       what interview !  \n4                                              sons of ,  \n...                                                  ...  \n27476                                denver husband lost  \n27477                                      i ve wondered  \n27478                                       yay good for  \n27479                                       it was worth  \n27480     All this flirting going on - The ATG smiles...  \n\n[27480 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>selected_text</th>\n      <th>sentiment</th>\n      <th>pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cb774db0d1</td>\n      <td>I`d have responded, if I were going</td>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n      <td>I`d have responded, if I were going</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>549e992a42</td>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>Sooo SAD</td>\n      <td>negative</td>\n      <td>sooo sad i</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>088c60f138</td>\n      <td>my boss is bullying me...</td>\n      <td>bullying me</td>\n      <td>negative</td>\n      <td>boss is bullying</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9642c003ef</td>\n      <td>what interview! leave me alone</td>\n      <td>leave me alone</td>\n      <td>negative</td>\n      <td>what interview !</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>358bd9e861</td>\n      <td>Sons of ****, why couldn`t they put them on t...</td>\n      <td>Sons of ****,</td>\n      <td>negative</td>\n      <td>sons of ,</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>27476</th>\n      <td>4eac33d1c0</td>\n      <td>wish we could come see u on Denver  husband l...</td>\n      <td>d lost</td>\n      <td>negative</td>\n      <td>denver husband lost</td>\n    </tr>\n    <tr>\n      <th>27477</th>\n      <td>4f4c4fc327</td>\n      <td>I`ve wondered about rake to.  The client has ...</td>\n      <td>, don`t force</td>\n      <td>negative</td>\n      <td>i ve wondered</td>\n    </tr>\n    <tr>\n      <th>27478</th>\n      <td>f67aae2310</td>\n      <td>Yay good for both of you. Enjoy the break - y...</td>\n      <td>Yay good for both of you.</td>\n      <td>positive</td>\n      <td>yay good for</td>\n    </tr>\n    <tr>\n      <th>27479</th>\n      <td>ed167662a5</td>\n      <td>But it was worth it  ****.</td>\n      <td>But it was worth it  ****.</td>\n      <td>positive</td>\n      <td>it was worth</td>\n    </tr>\n    <tr>\n      <th>27480</th>\n      <td>6f7127d9d7</td>\n      <td>All this flirting going on - The ATG smiles...</td>\n      <td>All this flirting going on - The ATG smiles. Y...</td>\n      <td>neutral</td>\n      <td>All this flirting going on - The ATG smiles...</td>\n    </tr>\n  </tbody>\n</table>\n<p>27480 rows × 5 columns</p>\n</div>"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T06:49:31.424603Z","iopub.execute_input":"2025-06-26T06:49:31.424918Z","iopub.status.idle":"2025-06-26T06:49:31.433220Z","shell.execute_reply.started":"2025-06-26T06:49:31.424897Z","shell.execute_reply":"2025-06-26T06:49:31.432634Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"          textID                                               text sentiment\n0     f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral\n1     96d74cb729   Shanghai is also really exciting (precisely -...  positive\n2     eee518ae67  Recession hit Veronique Branquinho, she has to...  negative\n3     01082688c6                                        happy bday!  positive\n4     33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive\n...          ...                                                ...       ...\n3529  e5f0e6ef4b  its at 3 am, im very tired but i can`t sleep  ...  negative\n3530  416863ce47  All alone in this old house again.  Thanks for...  positive\n3531  6332da480c   I know what you mean. My little dog is sinkin...  negative\n3532  df1baec676  _sutra what is your next youtube video gonna b...  positive\n3533  469e15c5a8   http://twitpic.com/4woj2 - omgssh  ang cute n...  positive\n\n[3534 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>f87dea47db</td>\n      <td>Last session of the day  http://twitpic.com/67ezh</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>96d74cb729</td>\n      <td>Shanghai is also really exciting (precisely -...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>eee518ae67</td>\n      <td>Recession hit Veronique Branquinho, she has to...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01082688c6</td>\n      <td>happy bday!</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>33987a8ee5</td>\n      <td>http://twitpic.com/4w75p - I like it!!</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3529</th>\n      <td>e5f0e6ef4b</td>\n      <td>its at 3 am, im very tired but i can`t sleep  ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3530</th>\n      <td>416863ce47</td>\n      <td>All alone in this old house again.  Thanks for...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3531</th>\n      <td>6332da480c</td>\n      <td>I know what you mean. My little dog is sinkin...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>3532</th>\n      <td>df1baec676</td>\n      <td>_sutra what is your next youtube video gonna b...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3533</th>\n      <td>469e15c5a8</td>\n      <td>http://twitpic.com/4woj2 - omgssh  ang cute n...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n<p>3534 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"subm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T06:48:46.530625Z","iopub.execute_input":"2025-06-26T06:48:46.531028Z","iopub.status.idle":"2025-06-26T06:48:46.541836Z","shell.execute_reply.started":"2025-06-26T06:48:46.530996Z","shell.execute_reply":"2025-06-26T06:48:46.541163Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"          textID  selected_text\n0     f87dea47db            NaN\n1     96d74cb729            NaN\n2     eee518ae67            NaN\n3     01082688c6            NaN\n4     33987a8ee5            NaN\n...          ...            ...\n3529  e5f0e6ef4b            NaN\n3530  416863ce47            NaN\n3531  6332da480c            NaN\n3532  df1baec676            NaN\n3533  469e15c5a8            NaN\n\n[3534 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>selected_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>f87dea47db</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>96d74cb729</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>eee518ae67</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01082688c6</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>33987a8ee5</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3529</th>\n      <td>e5f0e6ef4b</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3530</th>\n      <td>416863ce47</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3531</th>\n      <td>6332da480c</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3532</th>\n      <td>df1baec676</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3533</th>\n      <td>469e15c5a8</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>3534 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"import re\nimport pandas as pd\nfrom nltk.corpus import opinion_lexicon\nfrom nltk.tokenize import word_tokenize\n\n# 0. Jaccard функция с защитой от NaN\n\ndef jaccard(str1, str2):\n    \"\"\"\n    Word-level Jaccard similarity между двумя строками.\n    Корректно обрабатывает NaN, преобразуя их в пустые строки.\n    \"\"\"\n    s1 = str(str1).lower().split()\n    s2 = str(str2).lower().split()\n    a = set(s1)\n    b = set(s2)\n    if not a and not b:\n        return 1.0\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))\n\n# 1. Загрузка данных\ntrain = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\ntest = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')\n\n# 2. Предобработка текста\n\ndef clean_text(text: str) -> str:\n    \"\"\"\n    Очищает текст: приводит к нижнему регистру, убирает ссылки и упоминания, лишние пробелы.\n    Корректно обрабатывает NaN (преобразуя в пустую строку).\n    \"\"\"\n    text = str(text).lower()\n    text = re.sub(r'http\\S+|www\\S+', '', text)\n    text = re.sub(r'@\\w+', '', text)\n    text = re.sub(r'[^a-z0-9\\s\\.,!\\?\\'\\\"-]', ' ', text)\n    text = re.sub(r'\\s+', ' ', text).strip()\n    return text\n\n# 3. Простая эвристика по лексикону Opinion Lexicon\npos_words = set(opinion_lexicon.positive())\nneg_words = set(opinion_lexicon.negative())\n\ndef sentiment_score(tokens: list[str]) -> int:\n    \"\"\"\n    Считает разницу между количеством положительных и отрицательных слов в списке токенов.\n    \"\"\"\n    return sum(1 for w in tokens if w in pos_words) - sum(1 for w in tokens if w in neg_words)\n\n\ndef extract_by_lexicon(text: str, sentiment: str, window_size: int = 3) -> str:\n    \"\"\"\n    Для нейтрального твита возвращает весь текст.\n    Для остальных выбирает фрагмент длиной {window_size} слов с наибольшим лексическим score.\n    Корректно обрабатывает пустой или NaN текст.\n    \"\"\"\n    original = str(text) if pd.notna(text) else ''\n    cleaned = clean_text(text)\n    tokens = word_tokenize(cleaned)\n    if sentiment == 'neutral' or len(tokens) <= window_size:\n        return original\n\n    best_span = tokens[:window_size]\n    best_score = sentiment_score(best_span)\n    for i in range(len(tokens) - window_size + 1):\n        span = tokens[i:i + window_size]\n        sc = sentiment_score(span)\n        if (sentiment == 'positive' and sc > best_score) or (sentiment == 'negative' and sc < best_score):\n            best_score = sc\n            best_span = span\n\n    return ' '.join(best_span)\n\n# 4. Применение к train для проверки качества Jaccard\ntrain['pred'] = train.apply(lambda row: extract_by_lexicon(row.text, row.sentiment), axis=1)\ntrain['jaccard'] = train.apply(lambda r: jaccard(r.selected_text, r.pred), axis=1)\nprint(f\"Mean Jaccard: {train.jaccard.mean():.4f}\")\n\n# 5. Пример предсказания на test\nsubm = test[['textID']].copy()\nsubm['selected_text'] = test.apply(lambda r: extract_by_lexicon(r.text, r.sentiment), axis=1)\nsubm.to_csv('submission.csv', index=False)\nprint(\"Создан файл submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2025-06-26T06:50:58.901580Z","iopub.execute_input":"2025-06-26T06:50:58.902206Z","iopub.status.idle":"2025-06-26T06:51:04.088411Z","shell.execute_reply.started":"2025-06-26T06:50:58.902183Z","shell.execute_reply":"2025-06-26T06:51:04.087534Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import FeatureUnion, Pipeline\nfrom sklearn.preprocessing import FunctionTransformer, OneHotEncoder\nfrom lightgbm import LGBMClassifier\n\n# 1. Helper: sliding window span generator (safely handles NaNs)\ndef generate_spans(text, max_len=5):\n    text = str(text)\n    tokens = text.split()\n    spans = []\n    n = len(tokens)\n    for length in range(1, min(max_len, n) + 1):\n        for start in range(n - length + 1):\n            span = \" \".join(tokens[start:start + length])\n            spans.append(span)\n    return list(set(spans))\n\n# 2. Load data\ndata = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\ntest = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')\n\n# 3. Build training examples\nneg_examples = []\nfor _, row in data.iterrows():\n    text = row.text\n    selected = row.selected_text\n    sentiment = row.sentiment\n    if pd.isna(text) or pd.isna(selected):\n        continue\n    # positive example\n    eg = {'span': selected, 'sentiment': sentiment, 'label': 1}\n    neg_examples.append(eg)\n    # sample negatives\n    candidates = generate_spans(text)\n    negs = [s for s in candidates if s.lower() != str(selected).lower()]\n    if negs:\n        sampled = np.random.choice(negs, min(3, len(negs)), replace=False)\n        for s in sampled:\n            neg_examples.append({'span': s, 'sentiment': sentiment, 'label': 0})\ntrain_df = pd.DataFrame(neg_examples)\n\n# 4. Feature engineering: TF-IDF on span + one-hot sentiment\ndef get_span(X): return X['span']\ndef get_sentiment(X): return X[['sentiment']]\nspan_vect = Pipeline([\n    ('extract', FunctionTransformer(get_span, validate=False)),\n    ('tfidf', TfidfVectorizer(ngram_range=(1,3), max_features=50000))\n])\nsent_vect = Pipeline([\n    ('extract', FunctionTransformer(get_sentiment, validate=False)),\n    ('ohe', OneHotEncoder())\n])\nfeatures = FeatureUnion([('span', span_vect), ('sentiment', sent_vect)])\n\n# 5. Train/validation split\ny = train_df.label\nX_train, X_val, y_train, y_val = train_test_split(train_df, y, stratify=y, test_size=0.1, random_state=42)\n\n# 6. Pipeline with LightGBM\npipeline = Pipeline([\n    ('features', features),\n    ('clf', LGBMClassifier(n_estimators=200, learning_rate=0.1, random_state=42))\n])\n\n# 7. Train and evaluate\npipeline.fit(X_train, y_train)\nprint(\"Validation accuracy:\", pipeline.score(X_val, y_val))\n\n# 8. Inference function\n\ndef predict_selected(text, sentiment, max_len=5):\n    if sentiment == 'neutral' or pd.isna(text):\n        return str(text)\n    spans = generate_spans(text, max_len)\n    df = pd.DataFrame({'span': spans, 'sentiment': sentiment})\n    probs = pipeline.predict_proba(df)[:, 1]\n    return spans[np.argmax(probs)]\n\n# 9. Create submission\nsub = []\nfor _, row in test.iterrows():\n    pred = predict_selected(row.text, row.sentiment)\n    sub.append({'textID': row.textID, 'selected_text': pred})\nsub_df = pd.DataFrame(sub)\nsub_df.to_csv('submission.csv', index=False)\nprint(\"Saved submission_lgbm.csv\")","metadata":{"execution":{"iopub.status.busy":"2025-06-26T07:02:01.647358Z","iopub.execute_input":"2025-06-26T07:02:01.648021Z","iopub.status.idle":"2025-06-26T07:02:22.904774Z","shell.execute_reply.started":"2025-06-26T07:02:01.647990Z","shell.execute_reply":"2025-06-26T07:02:22.904004Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom scipy.sparse import hstack\n\n# 1) Загрузка данных\ntrain = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\ntest  = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')\n\n# 2) Подготовка токенов и меток\n\ndef prepare_tokens(df):\n    rows = []\n    for _, r in df.iterrows():\n        text, sel = str(r.text), str(r.selected_text)\n        toks = text.split()\n        sel_toks = sel.split() if sel != 'nan' else []\n        start_idx = None\n        if sel_toks:\n            for i in range(len(toks) - len(sel_toks) + 1):\n                if toks[i:i+len(sel_toks)] == sel_toks:\n                    start_idx = i\n                    break\n        end_idx = start_idx + len(sel_toks) - 1 if start_idx is not None else None\n\n        for i, tok in enumerate(toks):\n            rows.append({\n                'token': tok,\n                'pos_idx': i,\n                'pos_rel': i / max(1, len(toks)-1),\n                'y_start': 1 if i == start_idx else 0,\n                'y_end':   1 if i == end_idx   else 0\n            })\n    return pd.DataFrame(rows)\n\ndf_tokens = prepare_tokens(train)\n\n# 3) TF-IDF признаков\ntfidf = TfidfVectorizer(analyzer='word', token_pattern=r\"(?u)\\b\\w+\\b\", lowercase=True)\nX_tok_tfidf = tfidf.fit_transform(df_tokens['token'])\n\n# 4) Сбор всех признаков\nX_pos = df_tokens[['pos_idx','pos_rel']].values\nX = hstack([X_tok_tfidf, X_pos])\ny_start = df_tokens['y_start'].values\ny_end   = df_tokens['y_end'].values\n\n# 5) Сплит и обучение\nX_tr, X_val, ys_tr, ys_val = train_test_split(X, y_start, test_size=0.1, random_state=42)\n_, _, ye_tr, ye_val = train_test_split(X, y_end,   test_size=0.1, random_state=42)\n\nclf_start = LogisticRegression(max_iter=200)\nclf_end   = LogisticRegression(max_iter=200)\nclf_start.fit(X_tr, ys_tr)\nclf_end.fit(X_tr, ye_tr)\n\n# 6) Функция предсказания\n\ndef predict_selected(text):\n    toks = text.split()\n    if not toks:\n        return \"\"\n    tf = tfidf.transform(toks)\n    pos_idx = np.arange(len(toks))[:, None]\n    pos_rel = (pos_idx / max(1, len(toks)-1))\n    Xnew = hstack([tf, np.hstack([pos_idx, pos_rel])])\n\n    p_start = clf_start.predict_proba(Xnew)[:,1]\n    p_end   = clf_end  .predict_proba(Xnew)[:,1]\n\n    best_score = 0\n    bi, bj = 0, 0\n    for i in range(len(toks)):\n        for j in range(i, len(toks)):\n            score = p_start[i] * p_end[j]\n            if score > best_score:\n                best_score, bi, bj = score, i, j\n\n    return ' '.join(toks[bi:bj+1])\n\n# 7) Применение к тесту и сохранение сабмита\n\ndef build_submission(test_df, out_path='submission.csv'):\n    preds = []\n    for _, r in test_df.iterrows():\n        pred = predict_selected(str(r.text))\n        # Для neutral можно вернуть весь текст, если pred пустой\n        if not pred or r.sentiment == 'neutral':\n            pred = r.text\n        preds.append(pred)\n\n    subm = pd.DataFrame({'textID': test_df.textID, 'selected_text': preds})\n    subm.to_csv(out_path, index=False)\n    print(f\"Saved submission to {out_path}\")\n\n# Запуск\nbuild_submission(test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T07:05:26.748940Z","iopub.execute_input":"2025-06-26T07:05:26.749257Z","iopub.status.idle":"2025-06-26T07:05:49.909371Z","shell.execute_reply.started":"2025-06-26T07:05:26.749236Z","shell.execute_reply":"2025-06-26T07:05:49.908478Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/684737429.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;31m# Запуск\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m \u001b[0mbuild_submission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_35/684737429.py\u001b[0m in \u001b[0;36mbuild_submission\u001b[0;34m(test_df, out_path)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0msubm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'textID'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtextID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'selected_text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0msubm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquoting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQUOTE_ALL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Saved submission to {out_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'pandas.io.common' has no attribute 'csv'"],"ename":"AttributeError","evalue":"module 'pandas.io.common' has no attribute 'csv'","output_type":"error"}],"execution_count":34},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}