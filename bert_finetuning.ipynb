{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":101242,"databundleVersionId":12192519,"sourceType":"competition"}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"a524c90f-4847-408d-b8d6-fc02b7e6cc3e","_cell_guid":"693044dd-3901-400f-bda1-a43bae0a9ac9","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-11T05:14:21.015992Z","iopub.execute_input":"2025-06-11T05:14:21.016347Z","iopub.status.idle":"2025-06-11T05:14:22.786367Z","shell.execute_reply.started":"2025-06-11T05:14:21.016318Z","shell.execute_reply":"2025-06-11T05:14:22.785620Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"/kaggle/input/kazakhstan-respa-final-day-2-late-competition/sample_submission.csv\n/kaggle/input/kazakhstan-respa-final-day-2-late-competition/test_sentences.csv\n/kaggle/input/kazakhstan-respa-final-day-2-late-competition/train_sentences.csv\n/kaggle/input/kazakhstan-respa-final-day-2-late-competition/train_timeseries.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/kazakhstan-respa-final-day-2-late-competition/train_sentences.csv')\ntrain","metadata":{"_uuid":"4b2d6997-9ae8-46d6-811d-c0ba4fe46494","_cell_guid":"195e425c-6a61-4a30-9dd1-38afbf0a2653","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-11T05:14:22.787227Z","iopub.execute_input":"2025-06-11T05:14:22.787634Z","iopub.status.idle":"2025-06-11T05:14:23.120456Z","shell.execute_reply.started":"2025-06-11T05:14:22.787606Z","shell.execute_reply":"2025-06-11T05:14:23.119774Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"            submitted_date                                          sentences  \\\n0      2000-05-25 01:07:16  We give a summary of recent results on spatial...   \n1      2000-09-29 17:10:21  We study properties of the oscillation effects...   \n2      2000-10-04 09:40:11  Motivated by observations of supernova SN 1987...   \n3      2000-07-02 04:10:19  The abundance of oxygen was determined for sel...   \n4      2000-09-04 16:35:10  The 0th, 1st and 2nd derivatives of a ``Fermat...   \n...                    ...                                                ...   \n37172  2025-01-31 17:35:21  Causal Bayesian networks are 'causal' models s...   \n37173  2025-03-21 14:27:41  The Friedman test has been extensively applied...   \n37174  2025-02-21 10:08:28  In this paper, we propose a novel Bayesian app...   \n37175  2025-04-04 14:17:45  We consider a classical First-order Vector Aut...   \n37176  2025-02-18 16:19:28  We derived the closed-form asymptotic optimism...   \n\n                                         full_categories  \n0                                           ['astro-ph']  \n1                       ['hep-ph', 'astro-ph', 'hep-ex']  \n2                                           ['astro-ph']  \n3                                           ['astro-ph']  \n4                                           ['astro-ph']  \n...                                                  ...  \n37172  ['stat.ML', 'cs.AI', 'cs.LG', 'math.ST', 'stat...  \n37173                  ['stat.ME', 'math.ST', 'stat.TH']  \n37174                             ['math.ST', 'stat.TH']  \n37175                             ['math.ST', 'stat.TH']  \n37176         ['stat.ML', 'cs.LG', 'math.ST', 'stat.TH']  \n\n[37177 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>submitted_date</th>\n      <th>sentences</th>\n      <th>full_categories</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2000-05-25 01:07:16</td>\n      <td>We give a summary of recent results on spatial...</td>\n      <td>['astro-ph']</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2000-09-29 17:10:21</td>\n      <td>We study properties of the oscillation effects...</td>\n      <td>['hep-ph', 'astro-ph', 'hep-ex']</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2000-10-04 09:40:11</td>\n      <td>Motivated by observations of supernova SN 1987...</td>\n      <td>['astro-ph']</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2000-07-02 04:10:19</td>\n      <td>The abundance of oxygen was determined for sel...</td>\n      <td>['astro-ph']</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2000-09-04 16:35:10</td>\n      <td>The 0th, 1st and 2nd derivatives of a ``Fermat...</td>\n      <td>['astro-ph']</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>37172</th>\n      <td>2025-01-31 17:35:21</td>\n      <td>Causal Bayesian networks are 'causal' models s...</td>\n      <td>['stat.ML', 'cs.AI', 'cs.LG', 'math.ST', 'stat...</td>\n    </tr>\n    <tr>\n      <th>37173</th>\n      <td>2025-03-21 14:27:41</td>\n      <td>The Friedman test has been extensively applied...</td>\n      <td>['stat.ME', 'math.ST', 'stat.TH']</td>\n    </tr>\n    <tr>\n      <th>37174</th>\n      <td>2025-02-21 10:08:28</td>\n      <td>In this paper, we propose a novel Bayesian app...</td>\n      <td>['math.ST', 'stat.TH']</td>\n    </tr>\n    <tr>\n      <th>37175</th>\n      <td>2025-04-04 14:17:45</td>\n      <td>We consider a classical First-order Vector Aut...</td>\n      <td>['math.ST', 'stat.TH']</td>\n    </tr>\n    <tr>\n      <th>37176</th>\n      <td>2025-02-18 16:19:28</td>\n      <td>We derived the closed-form asymptotic optimism...</td>\n      <td>['stat.ML', 'cs.LG', 'math.ST', 'stat.TH']</td>\n    </tr>\n  </tbody>\n</table>\n<p>37177 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"train['submitted_date'] = pd.to_datetime(train['submitted_date'])","metadata":{"_uuid":"29cf1c95-ab75-40bc-9c63-8315cc15d9d3","_cell_guid":"3a6255db-e343-424e-9ebb-ff968c68e062","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-11T05:14:23.122241Z","iopub.execute_input":"2025-06-11T05:14:23.122450Z","iopub.status.idle":"2025-06-11T05:14:23.146345Z","shell.execute_reply.started":"2025-06-11T05:14:23.122433Z","shell.execute_reply":"2025-06-11T05:14:23.145332Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train['submitted_date'] = train['submitted_date'].dt.year","metadata":{"_uuid":"cdb4193a-4073-4d08-9497-32ff64a84615","_cell_guid":"ffd90f8a-80c5-4ec8-ac83-7f953d16ee9a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-11T05:14:23.146853Z","iopub.execute_input":"2025-06-11T05:14:23.147061Z","iopub.status.idle":"2025-06-11T05:14:23.170680Z","shell.execute_reply.started":"2025-06-11T05:14:23.147043Z","shell.execute_reply":"2025-06-11T05:14:23.169888Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train","metadata":{"_uuid":"7c47112c-dbc3-47a2-bb84-03eb388ad9e7","_cell_guid":"da1c84ff-b464-42ab-96f2-fbe7c8b162a5","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-11T05:14:23.171227Z","iopub.execute_input":"2025-06-11T05:14:23.171480Z","iopub.status.idle":"2025-06-11T05:14:23.191661Z","shell.execute_reply.started":"2025-06-11T05:14:23.171458Z","shell.execute_reply":"2025-06-11T05:14:23.190477Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"       submitted_date                                          sentences  \\\n0                2000  We give a summary of recent results on spatial...   \n1                2000  We study properties of the oscillation effects...   \n2                2000  Motivated by observations of supernova SN 1987...   \n3                2000  The abundance of oxygen was determined for sel...   \n4                2000  The 0th, 1st and 2nd derivatives of a ``Fermat...   \n...               ...                                                ...   \n37172            2025  Causal Bayesian networks are 'causal' models s...   \n37173            2025  The Friedman test has been extensively applied...   \n37174            2025  In this paper, we propose a novel Bayesian app...   \n37175            2025  We consider a classical First-order Vector Aut...   \n37176            2025  We derived the closed-form asymptotic optimism...   \n\n                                         full_categories  \n0                                           ['astro-ph']  \n1                       ['hep-ph', 'astro-ph', 'hep-ex']  \n2                                           ['astro-ph']  \n3                                           ['astro-ph']  \n4                                           ['astro-ph']  \n...                                                  ...  \n37172  ['stat.ML', 'cs.AI', 'cs.LG', 'math.ST', 'stat...  \n37173                  ['stat.ME', 'math.ST', 'stat.TH']  \n37174                             ['math.ST', 'stat.TH']  \n37175                             ['math.ST', 'stat.TH']  \n37176         ['stat.ML', 'cs.LG', 'math.ST', 'stat.TH']  \n\n[37177 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>submitted_date</th>\n      <th>sentences</th>\n      <th>full_categories</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2000</td>\n      <td>We give a summary of recent results on spatial...</td>\n      <td>['astro-ph']</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2000</td>\n      <td>We study properties of the oscillation effects...</td>\n      <td>['hep-ph', 'astro-ph', 'hep-ex']</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2000</td>\n      <td>Motivated by observations of supernova SN 1987...</td>\n      <td>['astro-ph']</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2000</td>\n      <td>The abundance of oxygen was determined for sel...</td>\n      <td>['astro-ph']</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2000</td>\n      <td>The 0th, 1st and 2nd derivatives of a ``Fermat...</td>\n      <td>['astro-ph']</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>37172</th>\n      <td>2025</td>\n      <td>Causal Bayesian networks are 'causal' models s...</td>\n      <td>['stat.ML', 'cs.AI', 'cs.LG', 'math.ST', 'stat...</td>\n    </tr>\n    <tr>\n      <th>37173</th>\n      <td>2025</td>\n      <td>The Friedman test has been extensively applied...</td>\n      <td>['stat.ME', 'math.ST', 'stat.TH']</td>\n    </tr>\n    <tr>\n      <th>37174</th>\n      <td>2025</td>\n      <td>In this paper, we propose a novel Bayesian app...</td>\n      <td>['math.ST', 'stat.TH']</td>\n    </tr>\n    <tr>\n      <th>37175</th>\n      <td>2025</td>\n      <td>We consider a classical First-order Vector Aut...</td>\n      <td>['math.ST', 'stat.TH']</td>\n    </tr>\n    <tr>\n      <th>37176</th>\n      <td>2025</td>\n      <td>We derived the closed-form asymptotic optimism...</td>\n      <td>['stat.ML', 'cs.LG', 'math.ST', 'stat.TH']</td>\n    </tr>\n  </tbody>\n</table>\n<p>37177 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport time\nimport datetime\nimport gc\nimport random\nfrom nltk.corpus import stopwords\nimport re\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler,random_split\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\nimport transformers\nfrom transformers import BertForSequenceClassification, BertConfig,BertTokenizer,get_linear_schedule_with_warmup, DistilBertForSequenceClassification, DistilBertTokenizer","metadata":{"_uuid":"fda8c284-5733-4cfb-9cba-12bfc99b8cc8","_cell_guid":"f3a7d822-7060-4193-a924-ee4d15d04e43","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-11T05:14:23.192208Z","iopub.execute_input":"2025-06-11T05:14:23.192421Z","iopub.status.idle":"2025-06-11T05:14:48.984390Z","shell.execute_reply.started":"2025-06-11T05:14:23.192402Z","shell.execute_reply":"2025-06-11T05:14:48.983814Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stderr","text":"2025-06-11 05:14:37.898972: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749618878.094636      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749618878.150268      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"sw = stopwords.words('english')\n\ndef clean_text(text):\n    \n    text = text.lower()\n    \n    text = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", text) # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n\n    text = re.sub(r\"http\\S+\", \"\",text) #Removing URLs \n    #text = re.sub(r\"http\", \"\",text)\n    \n    html=re.compile(r'<.*?>') \n    \n    text = html.sub(r'',text) #Removing html tags\n    \n    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\" + '_'\n    for p in punctuations:\n        text = text.replace(p,'') #Removing punctuations\n        \n    text = [word.lower() for word in text.split() if word.lower() not in sw]\n    \n    text = \" \".join(text) #removing stopwords\n    \n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text) #Removing emojis\n    \n    return text","metadata":{"_uuid":"9cdabd2f-6760-47cd-b789-c24cbc6d1220","_cell_guid":"8b0e085d-d1f7-4239-80e5-c5f4e36d6a4e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-11T05:14:48.985057Z","iopub.execute_input":"2025-06-11T05:14:48.985461Z","iopub.status.idle":"2025-06-11T05:14:48.994910Z","shell.execute_reply.started":"2025-06-11T05:14:48.985443Z","shell.execute_reply":"2025-06-11T05:14:48.994238Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"tweets = train['sentences'].apply(lambda x: clean_text(x))\n\nlabels = train['submitted_date']","metadata":{"_uuid":"8f08277d-fd2d-4946-a655-eade83790420","_cell_guid":"861fa255-db0c-4f56-a13f-7421ae357240","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-11T05:14:48.995669Z","iopub.execute_input":"2025-06-11T05:14:48.995954Z","iopub.status.idle":"2025-06-11T05:14:53.915126Z","shell.execute_reply.started":"2025-06-11T05:14:48.995928Z","shell.execute_reply":"2025-06-11T05:14:53.914591Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nimport numpy as np\n\n# предположим, у вас train['submitted_date'] → year_ids\nle = LabelEncoder()\nyear_ids = le.fit_transform(train['submitted_date'])\nprint(\"Уникальные годовые метки:\", np.unique(year_ids))\nprint(\"Классы LabelEncoder:\", le.classes_)\nn_classes = len(le.classes_)\nprint(\"num_labels:\", n_classes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T05:14:53.917730Z","iopub.execute_input":"2025-06-11T05:14:53.917926Z","iopub.status.idle":"2025-06-11T05:14:53.927860Z","shell.execute_reply.started":"2025-06-11T05:14:53.917911Z","shell.execute_reply":"2025-06-11T05:14:53.927167Z"}},"outputs":[{"name":"stdout","text":"Уникальные годовые метки: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25]\nКлассы LabelEncoder: [2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013\n 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025]\nnum_labels: 26\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"year_ids[:100]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T05:14:53.931181Z","iopub.execute_input":"2025-06-11T05:14:53.931365Z","iopub.status.idle":"2025-06-11T05:14:54.048885Z","shell.execute_reply.started":"2025-06-11T05:14:53.931350Z","shell.execute_reply":"2025-06-11T05:14:54.048228Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,\n        1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,\n        3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,\n        5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,\n        6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,\n        8,  8,  8,  8,  8, 19,  3,  3,  3,  4,  4,  4,  5,  5,  5])"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"labels[:100]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T05:14:54.049711Z","iopub.execute_input":"2025-06-11T05:14:54.049970Z","iopub.status.idle":"2025-06-11T05:14:54.067617Z","shell.execute_reply.started":"2025-06-11T05:14:54.049951Z","shell.execute_reply":"2025-06-11T05:14:54.066894Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"0     2000\n1     2000\n2     2000\n3     2000\n4     2000\n      ... \n95    2004\n96    2004\n97    2005\n98    2005\n99    2005\nName: submitted_date, Length: 100, dtype: int32"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"labels = year_ids","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T05:14:54.068268Z","iopub.execute_input":"2025-06-11T05:14:54.068533Z","iopub.status.idle":"2025-06-11T05:14:54.082752Z","shell.execute_reply.started":"2025-06-11T05:14:54.068511Z","shell.execute_reply":"2025-06-11T05:14:54.082061Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"_uuid":"9e4626c1-63aa-4bf4-bd72-6fedf6d624e3","_cell_guid":"f965b047-1682-40b9-b19f-5df371978f10","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-11T05:14:54.083443Z","iopub.execute_input":"2025-06-11T05:14:54.083777Z","iopub.status.idle":"2025-06-11T05:14:54.099208Z","shell.execute_reply.started":"2025-06-11T05:14:54.083760Z","shell.execute_reply":"2025-06-11T05:14:54.098679Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"modelname = \"distilbert-base-uncased\"\n# modelname = 'distilroberta-base'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T05:14:54.099877Z","iopub.execute_input":"2025-06-11T05:14:54.100093Z","iopub.status.idle":"2025-06-11T05:14:54.113040Z","shell.execute_reply.started":"2025-06-11T05:14:54.100077Z","shell.execute_reply":"2025-06-11T05:14:54.112322Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"tokenizer = DistilBertTokenizer.from_pretrained(modelname, do_lower_case=True)","metadata":{"_uuid":"52237f5e-7015-43b0-98bb-ba306f4ce65d","_cell_guid":"9a4f9f05-496d-44f6-9b38-61b7aa0add72","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-11T05:14:54.113920Z","iopub.execute_input":"2025-06-11T05:14:54.114198Z","iopub.status.idle":"2025-06-11T05:14:57.238959Z","shell.execute_reply.started":"2025-06-11T05:14:54.114163Z","shell.execute_reply":"2025-06-11T05:14:57.238238Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6811d4e09e9b44029d5d4a3a9323b850"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c69094815a714d4e87441747b7fac9a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"831793125fad450a92e22f155806489a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8eaf35bf1e7a4d628f482a50c95c0e05"}},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"print(' Original: ', tweets[0])\n\n# Print the sentence split into tokens.\nprint('Tokenized: ', tokenizer.tokenize(tweets[0]))\n\n# Print the sentence mapped to token ids.\nprint('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(tweets[0])))","metadata":{"_uuid":"cc83eb9a-8bac-426b-95e7-927c00fc3ce5","_cell_guid":"ce39686c-17e8-4501-b675-5bf03b13a4d6","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-11T05:14:57.239702Z","iopub.execute_input":"2025-06-11T05:14:57.239926Z","iopub.status.idle":"2025-06-11T05:14:57.246009Z","shell.execute_reply.started":"2025-06-11T05:14:57.239908Z","shell.execute_reply":"2025-06-11T05:14:57.245265Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":" Original:  give summary recent results spatial velocity biases cosmological models progress numerical techniques made possible simulate halos large volumes accuracy halos survive dense environments groups clusters galaxies\nTokenized:  ['give', 'summary', 'recent', 'results', 'spatial', 'velocity', 'bias', '##es', 'co', '##smo', '##logical', 'models', 'progress', 'numerical', 'techniques', 'made', 'possible', 'simulate', 'halo', '##s', 'large', 'volumes', 'accuracy', 'halo', '##s', 'survive', 'dense', 'environments', 'groups', 'clusters', 'galaxies']\nToken IDs:  [2507, 12654, 3522, 3463, 13589, 10146, 13827, 2229, 2522, 25855, 9966, 4275, 5082, 15973, 5461, 2081, 2825, 26633, 17201, 2015, 2312, 6702, 10640, 17201, 2015, 5788, 9742, 10058, 2967, 12906, 21706]\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"max_len = 0\n\n# For every sentence...\nfor sent in tweets:\n\n    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n\n    # Update the maximum sentence length.\n    max_len = max(max_len, len(input_ids))\n\nprint('Max sentence length: ', max_len)","metadata":{"_uuid":"48b9920b-61d9-4652-b95c-0a4a2c45d0de","_cell_guid":"b6c1ec2d-bd7c-4d99-9022-373301424bfe","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-11T05:14:57.246850Z","iopub.execute_input":"2025-06-11T05:14:57.247078Z","iopub.status.idle":"2025-06-11T05:15:23.206764Z","shell.execute_reply.started":"2025-06-11T05:14:57.247053Z","shell.execute_reply":"2025-06-11T05:15:23.206084Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"Max sentence length:  275\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"max_len = 256","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T05:15:23.207416Z","iopub.execute_input":"2025-06-11T05:15:23.207630Z","iopub.status.idle":"2025-06-11T05:15:23.211044Z","shell.execute_reply.started":"2025-06-11T05:15:23.207613Z","shell.execute_reply":"2025-06-11T05:15:23.210357Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"input_ids = []\nattention_masks = []\n\n# For every tweet...\nfor tweet in tweets:\n    # `encode_plus` will:\n    #   (1) Tokenize the sentence.\n    #   (2) Prepend the `[CLS]` token to the start.\n    #   (3) Append the `[SEP]` token to the end.\n    #   (4) Map tokens to their IDs.\n    #   (5) Pad or truncate the sentence to `max_length`\n    #   (6) Create attention masks for [PAD] tokens.\n    encoded_dict = tokenizer.encode_plus(\n                        tweet,                      # Sentence to encode.\n                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n                        max_length = max_len,           # Pad & truncate all sentences.\n                        pad_to_max_length = True,\n                        return_attention_mask = True,   # Construct attn. masks.\n                        return_tensors = 'pt',     # Return pytorch tensors.\n                   )\n    \n    # Add the encoded sentence to the list.    \n    input_ids.append(encoded_dict['input_ids'])\n    \n    # And its attention mask (simply differentiates padding from non-padding).\n    attention_masks.append(encoded_dict['attention_mask'])\n\n# Convert the lists into tensors.\ninput_ids = torch.cat(input_ids, dim=0)\nattention_masks = torch.cat(attention_masks, dim=0)\nlabels = torch.tensor(labels)\n\n# Print sentence 0, now as a list of IDs.\nprint('Original: ', tweets[0])\nprint('Token IDs:', input_ids[0])","metadata":{"_uuid":"6268b80b-08ff-45f5-9912-a2e566e08dfa","_cell_guid":"f6110afc-1f72-49c2-a0a6-076c10dc1166","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-11T05:15:23.211788Z","iopub.execute_input":"2025-06-11T05:15:23.212126Z","iopub.status.idle":"2025-06-11T05:15:56.209041Z","shell.execute_reply.started":"2025-06-11T05:15:23.212098Z","shell.execute_reply":"2025-06-11T05:15:56.208264Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2700: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Original:  give summary recent results spatial velocity biases cosmological models progress numerical techniques made possible simulate halos large volumes accuracy halos survive dense environments groups clusters galaxies\nToken IDs: tensor([  101,  2507, 12654,  3522,  3463, 13589, 10146, 13827,  2229,  2522,\n        25855,  9966,  4275,  5082, 15973,  5461,  2081,  2825, 26633, 17201,\n         2015,  2312,  6702, 10640, 17201,  2015,  5788,  9742, 10058,  2967,\n        12906, 21706,   102,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0])\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"dataset = TensorDataset(input_ids, attention_masks, labels)\n\n# Create a 90-10 train-validation split.\n\n# Calculate the number of samples to include in each set.\ntrain_size = int(0.8 * len(dataset))\n#val_size = int(0.2 * len(dataset))\nval_size = len(dataset)  - train_size\n\n# Divide the dataset by randomly selecting samples.\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\nprint('{:>5,} training samples'.format(train_size))\nprint('{:>5,} validation samples'.format(val_size))","metadata":{"_uuid":"7e64cd5f-6bbe-4656-b379-464d5e24735f","_cell_guid":"befdcfb3-ccc7-49ec-9df2-a3f86b8222af","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-11T05:15:56.209894Z","iopub.execute_input":"2025-06-11T05:15:56.210543Z","iopub.status.idle":"2025-06-11T05:15:56.217805Z","shell.execute_reply.started":"2025-06-11T05:15:56.210524Z","shell.execute_reply":"2025-06-11T05:15:56.217110Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"29,741 training samples\n7,436 validation samples\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# The DataLoader needs to know our batch size for training, so we specify it \n# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n# size of 16 or 32.\nbatch_size = 16\n\n# Create the DataLoaders for our training and validation sets.\n# We'll take training samples in random order. \ntrain_dataloader = DataLoader(\n            train_dataset,  # The training samples.\n            sampler = RandomSampler(train_dataset), # Select batches randomly\n            batch_size = batch_size # Trains with this batch size.\n        )\n\n# For validation the order doesn't matter, so we'll just read them sequentially.\nvalidation_dataloader = DataLoader(\n            val_dataset, # The validation samples.\n            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n            batch_size = batch_size # Evaluate with this batch size.\n        )","metadata":{"_uuid":"f3bc075c-0f1e-4673-ac30-603e297c4a49","_cell_guid":"72741931-8111-484a-a469-8545ec218047","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-11T05:15:56.218581Z","iopub.execute_input":"2025-06-11T05:15:56.218911Z","iopub.status.idle":"2025-06-11T05:15:56.234287Z","shell.execute_reply.started":"2025-06-11T05:15:56.218894Z","shell.execute_reply":"2025-06-11T05:15:56.233605Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Load BertForSequenceClassification, the pretrained BERT model with a single \n# linear classification layer on top. \nmodel = DistilBertForSequenceClassification.from_pretrained(\n    modelname, # Use the 12-layer BERT model, with an uncased vocab.\n    num_labels = len(labels.unique()), # The number of output labels--2 for binary classification.\n                    # You can increase this for multi-class tasks.   \n    output_attentions = False, # Whether the model returns attentions weights.\n    output_hidden_states = False, # Whether the model returns all hidden-states.\n)\n\n# if device == \"cuda:0\":\n# # Tell pytorch to run this model on the GPU.\n#     model = model.cuda()\nmodel = model.to(device)","metadata":{"_uuid":"25e5e918-00b8-45b3-93cb-00f772d0789a","_cell_guid":"b0003281-7000-46ed-a6f5-6e74c5450772","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-11T05:15:56.235071Z","iopub.execute_input":"2025-06-11T05:15:56.235709Z","iopub.status.idle":"2025-06-11T05:16:00.785435Z","shell.execute_reply.started":"2025-06-11T05:15:56.235686Z","shell.execute_reply":"2025-06-11T05:16:00.784895Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60e34ce13b614fadadd9e65ed2e63763"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(),\n                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n                )","metadata":{"_uuid":"28dcfcd3-475e-4427-9785-73a397c1b730","_cell_guid":"35caf181-8b5b-41a8-b378-f0b1490a8b7b","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-11T05:16:00.786153Z","iopub.execute_input":"2025-06-11T05:16:00.786401Z","iopub.status.idle":"2025-06-11T05:16:00.790742Z","shell.execute_reply.started":"2025-06-11T05:16:00.786379Z","shell.execute_reply":"2025-06-11T05:16:00.790008Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# Number of training epochs. The BERT authors recommend between 2 and 4. \n# We chose to run for 4, but we'll see later that this may be over-fitting the\n# training data.\nepochs = 4\n\n# Total number of training steps is [number of batches] x [number of epochs]. \n# (Note that this is not the same as the number of training samples).\ntotal_steps = len(train_dataloader) * epochs\n\n# Create the learning rate scheduler.\nscheduler = get_linear_schedule_with_warmup(optimizer, \n                                            num_warmup_steps = 0, # Default value in run_glue.py\n                                            num_training_steps = total_steps)","metadata":{"_uuid":"6b3ed4ae-2c0d-4a06-9427-6233f34ec0a7","_cell_guid":"a768f712-fe7e-4a28-99e3-42723c75ef77","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-11T05:16:00.791269Z","iopub.execute_input":"2025-06-11T05:16:00.791442Z","iopub.status.idle":"2025-06-11T05:16:00.807667Z","shell.execute_reply.started":"2025-06-11T05:16:00.791428Z","shell.execute_reply":"2025-06-11T05:16:00.806982Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# Function to calculate the accuracy of our predictions vs labels\ndef flat_accuracy(preds, labels):\n    pred_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return np.sum(pred_flat == labels_flat) / len(labels_flat)","metadata":{"_uuid":"a3ed6023-eb33-4f4d-8fee-c420ba06750f","_cell_guid":"c04c3143-955e-4967-b469-7cc2ffc3f5f2","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-11T05:16:00.808361Z","iopub.execute_input":"2025-06-11T05:16:00.808573Z","iopub.status.idle":"2025-06-11T05:16:00.827286Z","shell.execute_reply.started":"2025-06-11T05:16:00.808534Z","shell.execute_reply":"2025-06-11T05:16:00.826583Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"def format_time(elapsed):\n    '''\n    Takes a time in seconds and returns a string hh:mm:ss\n    '''\n    # Round to the nearest second.\n    elapsed_rounded = int(round((elapsed)))\n    # Format as hh:mm:ss\n    return str(datetime.timedelta(seconds=elapsed_rounded))","metadata":{"_uuid":"352dcb2d-9c28-42ef-b538-c07232f07adc","_cell_guid":"d9dc0e5d-f443-4285-8727-37ed7eef02c2","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-11T05:16:00.831286Z","iopub.execute_input":"2025-06-11T05:16:00.831482Z","iopub.status.idle":"2025-06-11T05:16:00.844130Z","shell.execute_reply.started":"2025-06-11T05:16:00.831467Z","shell.execute_reply":"2025-06-11T05:16:00.843597Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\nseed_val = 42\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)\ntraining_stats = []\n\nfor epoch_i in range(epochs):\n    print(f\"\\n======== Epoch {epoch_i+1} / {epochs} ========\")\n    \n    # TRAINING\n    model.train()\n    total_train_loss = 0.0\n    \n    train_iter = tqdm(train_dataloader, desc=\"Train\", unit=\"batch\")\n    for batch in train_iter:\n        b_input_ids, b_input_mask, b_labels = [t.to(device) for t in batch]\n        b_labels = b_labels.long()\n        \n        optimizer.zero_grad()\n        outputs = model(\n            b_input_ids,\n            attention_mask=b_input_mask,\n            labels=b_labels\n        )\n        loss = outputs.loss\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        scheduler.step()\n        \n        batch_loss = loss.item()\n        total_train_loss += batch_loss\n        \n        # обновляем tqdm-бар: показываем текущий batch_loss\n        train_iter.set_postfix(train_loss=batch_loss)\n\n    # Calculate the average loss over all of the batches.\n    avg_train_loss = total_train_loss / len(train_dataloader)            \n    \n    # Measure how long this epoch took.\n    print(\"\")\n    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n    # ========================================\n    #               Validation\n    # ========================================\n    # After the completion of each training epoch, measure our performance on\n    # our validation set.\n    print(\"\")\n    print(\"Running Validation...\")\n    t0 = time.time()\n    # Put the model in evaluation mode--the dropout layers behave differently\n    # during evaluation.\n    model.eval()\n    # Tracking variables \n    total_eval_accuracy = 0\n    best_eval_accuracy = 0\n    total_eval_loss = 0\n    nb_eval_steps = 0\n    # Evaluate data for one epoch\n    for batch in validation_dataloader:\n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        b_labels = batch[2].to(device)\n        # Tell pytorch not to bother with constructing the compute graph during\n        # the forward pass, since this is only needed for backprop (training).\n        with torch.no_grad():        \n            output= model(b_input_ids, \n                                   attention_mask=b_input_mask,\n                                   labels=b_labels)\n        loss = output.loss\n        total_eval_loss += loss.item()\n        # Move logits and labels to CPU if we are using GPU\n        logits = output.logits\n        logits = logits.detach().cpu().numpy()\n        label_ids = b_labels.to('cpu').numpy()\n        # Calculate the accuracy for this batch of test sentences, and\n        # accumulate it over all batches.\n        total_eval_accuracy += flat_accuracy(logits, label_ids)\n    # Report the final accuracy for this validation run.\n    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n    # Calculate the average loss over all of the batches.\n    avg_val_loss = total_eval_loss / len(validation_dataloader)\n    # Measure how long the validation run took.\n    if avg_val_accuracy > best_eval_accuracy:\n        torch.save(model, 'bert_model')\n        best_eval_accuracy = avg_val_accuracy\n    #print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n    #print(\"  Validation took: {:}\".format(validation_time))\n    # Record all statistics from this epoch.\n    training_stats.append(\n        {\n            'epoch': epoch_i + 1,\n            'Training Loss': avg_train_loss,\n            'Valid. Loss': avg_val_loss,\n            'Valid. Accur.': avg_val_accuracy,\n        }\n    )\nprint(\"\")\nprint(\"Training complete!\")","metadata":{"_uuid":"e9f971ac-1cf9-4797-90cb-4dde777570d2","_cell_guid":"88b33312-df7e-4eaa-8df2-f642622223c4","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-06-11T05:16:00.844872Z","iopub.execute_input":"2025-06-11T05:16:00.845399Z"},"jupyter":{"outputs_hidden":false}},"outputs":[{"name":"stdout","text":"\n======== Epoch 1 / 4 ========\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train:   0%|          | 0/1859 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"144fb1361e094af2874f0952cf1d9be2"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"testpath = '/kaggle/input/kazakhstan-respa-final-day-2-late-competition/test_sentences.csv'\ndf_test = pd.read_csv(testpath)\ndf_test['text1'] = df_test['first_sentence'].apply(lambda x:clean_text(x))\ntest_tweets1 = df_test['text1'].values\ndf_test['text2'] = df_test['second_sentence'].apply(lambda x:clean_text(x))\ntest_tweets2 = df_test['text2'].values","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_input_ids1 = []\ntest_attention_masks1 = []\nfor tweet in test_tweets1:\n    encoded_dict = tokenizer.encode_plus(\n                        tweet,                     \n                        add_special_tokens = True, \n                        max_length = max_len,           \n                        pad_to_max_length = True,\n                        return_attention_mask = True,\n                        return_tensors = 'pt',\n                   )\n    test_input_ids1.append(encoded_dict['input_ids'])\n    test_attention_masks1.append(encoded_dict['attention_mask'])\ntest_input_ids1 = torch.cat(test_input_ids1, dim=0)\ntest_attention_masks1 = torch.cat(test_attention_masks1, dim=0)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_input_ids2 = []\ntest_attention_masks2 = []\nfor tweet in test_tweets2:\n    encoded_dict = tokenizer.encode_plus(\n                        tweet,                     \n                        add_special_tokens = True, \n                        max_length = max_len,           \n                        pad_to_max_length = True,\n                        return_attention_mask = True,\n                        return_tensors = 'pt',\n                   )\n    test_input_ids2.append(encoded_dict['input_ids'])\n    test_attention_masks2.append(encoded_dict['attention_mask'])\ntest_input_ids2 = torch.cat(test_input_ids2, dim=0)\ntest_attention_masks2 = torch.cat(test_attention_masks2, dim=0)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_dataset1 = TensorDataset(test_input_ids1, test_attention_masks1)\ntest_dataloader1 = DataLoader(\n            test_dataset1, # The validation samples.\n            sampler = SequentialSampler(test_dataset1), # Pull out batches sequentially.\n            batch_size = batch_size # Evaluate with this batch size.\n        )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_dataset2 = TensorDataset(test_input_ids2, test_attention_masks2)\ntest_dataloader2 = DataLoader(\n            test_dataset2, # The validation samples.\n            sampler = SequentialSampler(test_dataset2), # Pull out batches sequentially.\n            batch_size = batch_size # Evaluate with this batch size.\n        )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = torch.load('bert_model')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions1 = []\nfor batch in test_dataloader1:\n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        with torch.no_grad():        \n            output= model(b_input_ids, \n                                   attention_mask=b_input_mask)\n            logits = output.logits\n            logits = logits.detach().cpu().numpy()\n            pred_flat = np.argmax(logits, axis=1).flatten()\n            \n            predictions1.extend(list(pred_flat))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions1[:10]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions2 = []\nfor batch in test_dataloader2:\n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        with torch.no_grad():        \n            output= model(b_input_ids, \n                                   attention_mask=b_input_mask)\n            logits = output.logits\n            logits = logits.detach().cpu().numpy()\n            pred_flat = np.argmax(logits, axis=1).flatten()\n            \n            predictions2.extend(list(pred_flat))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions2[:10]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/kazakhstan-respa-final-day-2-late-competition/sample_submission.csv')\nsubmission","metadata":{"_uuid":"9749a849-65ee-4a11-bb89-9680f3540c7b","_cell_guid":"6a153705-8ca5-4577-95f0-5a188df9bc6e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"preds = []\nfor f, s in zip(predictions1, predictions2):\n    if f > s:\n        preds.append(0)\n    else:\n        preds.append(1)","metadata":{"_uuid":"26bf4b24-5262-4ae2-8cf0-a586929fdf1b","_cell_guid":"16f25b57-4801-4172-805b-407425018e66","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission['label'] = preds\nsubmission","metadata":{"_uuid":"0763c121-6927-4a92-b6a2-0d311675616f","_cell_guid":"3a61a4b9-5d89-4b2a-a0ca-e58c1997cdac","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission.to_csv('submission111.csv', index=False)","metadata":{"_uuid":"b52ffd3d-99f4-432f-9d47-b325551f5b1c","_cell_guid":"31f6bf66-41c3-4743-9bdc-71dc4dcc8475","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"_uuid":"dee573aa-4e11-467b-bef0-62c6e644fca2","_cell_guid":"42332756-a7ad-48d0-ab3c-27bb1894ac95","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}